const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  connectionTimeoutMillis: 30000,
  max: 10,
});

async function fastUploadSubmissions() {
  console.log('ğŸš€ å¿«é€Ÿä¸Šä¼ submission_statisticsæ•°æ®...\n');
  
  let client;
  try {
    client = await pool.connect();
    console.log('âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ\n');
    
    // Load submission data
    const submissionStatsPath = path.join(process.cwd(), 'calculated-stats', 'submission_stats.json');
    const submissionData = JSON.parse(fs.readFileSync(submissionStatsPath, 'utf8'));
    
    console.log(`ğŸ“Š å‘ç° ${submissionData.submissions.length} æ¡submissionè®°å½•`);
    
    // Clear existing data
    console.log('ğŸ—‘ï¸  æ¸…ç©ºç°æœ‰submission_statisticsæ•°æ®...');
    await client.query('DELETE FROM submission_statistics');
    
    // Create CSV data for COPY command
    console.log('ğŸ“ å‡†å¤‡CSVæ•°æ®...');
    const csvHeader = 'submission_id,submission_number,review_count,avg_rating,rating_std,avg_confidence,ethics_flag\n';
    const csvData = submissionData.submissions.map(submission => {
      return [
        submission.submission_id || '',
        submission.submission_number || 0,
        submission.review_count || 0,
        submission.avg_rating || 0,
        submission.rating_std || 0,
        submission.avg_confidence || 0,
        submission.ethics_flag || 0
      ].join(',');
    }).join('\n');
    
    const fullCsv = csvHeader + csvData;
    
    // Write to temporary file
    const tempCsvPath = '/tmp/submissions_upload.csv';
    fs.writeFileSync(tempCsvPath, fullCsv);
    console.log(`ğŸ“„ CSVæ–‡ä»¶å·²å†™å…¥: ${tempCsvPath}`);
    
    // Use COPY command for bulk insert
    console.log('âš¡ å¼€å§‹æ‰¹é‡å¯¼å…¥...');
    const copyQuery = `
      COPY submission_statistics (submission_id, submission_number, review_count, avg_rating, rating_std, avg_confidence, ethics_flag)
      FROM STDIN WITH CSV HEADER
    `;
    
    const stream = client.query(require('pg-copy-streams').from(copyQuery));
    const fileStream = fs.createReadStream(tempCsvPath);
    
    await new Promise((resolve, reject) => {
      stream.on('error', reject);
      stream.on('finish', resolve);
      fileStream.pipe(stream);
    });
    
    // Clean up temp file
    fs.unlinkSync(tempCsvPath);
    
    // Verify upload
    console.log('ğŸ” éªŒè¯ä¸Šä¼ ç»“æœ...');
    const finalCount = await client.query('SELECT COUNT(*) FROM submission_statistics');
    const minMax = await client.query(`
      SELECT 
        MIN(submission_number::int) as min_num, 
        MAX(submission_number::int) as max_num,
        AVG(review_count) as avg_reviews
      FROM submission_statistics
    `);
    
    console.log(`ğŸ“Š ä¸Šä¼ å®Œæˆç»Ÿè®¡:`);
    console.log(`  - æ€»è®°å½•æ•°: ${finalCount.rows[0].count}`);
    console.log(`  - è®ºæ–‡ç¼–å·èŒƒå›´: ${minMax.rows[0].min_num} - ${minMax.rows[0].max_num}`);
    console.log(`  - å¹³å‡è¯„å®¡æ•°: ${parseFloat(minMax.rows[0].avg_reviews).toFixed(2)}`);
    
    console.log('\nğŸ‰ submission_statisticsæ•°æ®å¿«é€Ÿä¸Šä¼ å®Œæˆï¼');
    console.log('ç°åœ¨æœç´¢åŠŸèƒ½åº”è¯¥å¯ä»¥æ‰¾åˆ°åŒ…æ‹¬7404åœ¨å†…çš„æ‰€æœ‰è®ºæ–‡äº†ã€‚');
    
  } catch (error) {
    console.error('âŒ ä¸Šä¼ å¤±è´¥:', error.message);
    
    // Fallback to batch insert if COPY fails
    if (error.message.includes('COPY') || error.message.includes('pg-copy-streams')) {
      console.log('\nğŸ”„ COPYå‘½ä»¤å¤±è´¥ï¼Œå›é€€åˆ°æ‰¹é‡æ’å…¥æ¨¡å¼...');
      await fallbackBatchInsert(client);
    } else {
      console.log('\nğŸ’¡ è¯·æ£€æŸ¥ï¼š');
      console.log('1. æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸');
      console.log('2. submission_statisticsè¡¨æ˜¯å¦å­˜åœ¨');
      console.log('3. calculated-stats/submission_stats.jsonæ–‡ä»¶æ˜¯å¦å­˜åœ¨');
    }
  } finally {
    if (client) client.release();
    await pool.end();
  }
}

async function fallbackBatchInsert(client) {
  const submissionStatsPath = path.join(process.cwd(), 'calculated-stats', 'submission_stats.json');
  const submissionData = JSON.parse(fs.readFileSync(submissionStatsPath, 'utf8'));
  
  console.log('ğŸ“¦ ä½¿ç”¨å¤§æ‰¹æ¬¡æ’å…¥æ¨¡å¼...');
  
  const batchSize = 2000; // å¢å¤§æ‰¹æ¬¡
  let uploaded = 0;
  
  for (let i = 0; i < submissionData.submissions.length; i += batchSize) {
    const batch = submissionData.submissions.slice(i, i + batchSize);
    
    console.log(`ğŸ“¤ ä¸Šä¼ æ‰¹æ¬¡ ${Math.floor(i/batchSize) + 1}: ${i + 1}-${Math.min(i + batchSize, submissionData.submissions.length)}`);
    
    // Build values array for multi-row insert
    const values = [];
    const placeholders = [];
    let paramIndex = 1;
    
    for (const submission of batch) {
      placeholders.push(`($${paramIndex}, $${paramIndex+1}, $${paramIndex+2}, $${paramIndex+3}, $${paramIndex+4}, $${paramIndex+5}, $${paramIndex+6})`);
      values.push(
        submission.submission_id,
        submission.submission_number,
        submission.review_count,
        submission.avg_rating,
        submission.rating_std,
        submission.avg_confidence,
        submission.ethics_flag
      );
      paramIndex += 7;
    }
    
    const insertQuery = `
      INSERT INTO submission_statistics 
      (submission_id, submission_number, review_count, avg_rating, rating_std, avg_confidence, ethics_flag)
      VALUES ${placeholders.join(', ')}
    `;
    
    await client.query(insertQuery, values);
    uploaded += batch.length;
    
    const progress = ((uploaded / submissionData.submissions.length) * 100).toFixed(1);
    console.log(`  âœ… æ‰¹æ¬¡å®Œæˆï¼Œå·²ä¸Šä¼  ${uploaded}/${submissionData.submissions.length} æ¡è®°å½• (${progress}%)`);
  }
}

if (require.main === module) {
  fastUploadSubmissions().catch(console.error);
}