#!/usr/bin/env python3
"""
ICLR å¼‚å¸¸æ£€æµ‹æ¨¡å—
æ£€æµ‹å¼‚å¸¸è¯„å®¡è¡Œä¸ºå’Œæ•°æ®è´¨é‡é—®é¢˜
"""

import json
import numpy as np
import pandas as pd
from collections import defaultdict, Counter
from datetime import datetime
import os
import statistics
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import shapiro, skew, kurtosis
from scipy.stats import zscore
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class AnomalyDetector:
    def __init__(self, reviews_data_path, people_data_path, institutions_data_path):
        """åˆå§‹åŒ–å¼‚å¸¸æ£€æµ‹å™¨"""
        print("ğŸ” å¯åŠ¨å¼‚å¸¸æ£€æµ‹æ¨¡å—...")
        
        # åŠ è½½æ•°æ®
        with open(reviews_data_path, 'r', encoding='utf-8') as f:
            self.reviews_data = json.load(f)
            
        with open(people_data_path, 'r', encoding='utf-8') as f:
            self.people_data = json.load(f)
            
        with open(institutions_data_path, 'r', encoding='utf-8') as f:
            self.institutions_data = json.load(f)
        
        # åˆå§‹åŒ–å¼‚å¸¸æ£€æµ‹ç»“æœ
        self.anomaly_results = {
            'reviewer_anomalies': {},
            'submission_anomalies': {},
            'rating_anomalies': {},
            'content_anomalies': {},
            'data_quality_issues': {},
            'summary_statistics': {}
        }
        
        print("âœ… æ•°æ®åŠ è½½å®Œæˆ")
    
    def detect_reviewer_anomalies(self):
        """æ£€æµ‹å¼‚å¸¸å®¡ç¨¿äººè¡Œä¸º"""
        print("\nğŸ‘¤ æ£€æµ‹å¼‚å¸¸å®¡ç¨¿äººè¡Œä¸º...")
        
        # æ„å»ºå®¡ç¨¿äººæ•°æ®
        reviewer_stats = defaultdict(lambda: {
            'ratings': [],
            'confidences': [],
            'text_lengths': [],
            'review_count': 0,
            'submission_numbers': [],
            'review_dates': [],
            'content_quality': []
        })
        
        # æ”¶é›†å®¡ç¨¿äººæ•°æ®
        for submission_num, submission_data in self.reviews_data['reviews'].items():
            for review in submission_data['reviews']:
                reviewer_id = review.get('reviewer_id')
                if not reviewer_id:
                    continue
                
                rating = review.get('rating')
                confidence = review.get('confidence')
                content = review.get('content', {})
                
                # è®¡ç®—æ–‡æœ¬é•¿åº¦
                summary_len = len(content.get('summary', '')) if content.get('summary') else 0
                strengths_len = len(content.get('strengths', '')) if content.get('strengths') else 0
                weaknesses_len = len(content.get('weaknesses', '')) if content.get('weaknesses') else 0
                questions_len = len(content.get('questions', '')) if content.get('questions') else 0
                total_len = summary_len + strengths_len + weaknesses_len + questions_len
                
                # å†…å®¹è´¨é‡åˆ†æ•°ï¼ˆåŸºäºé•¿åº¦å’Œå®Œæ•´æ€§ï¼‰
                content_quality = 0
                if summary_len > 50:
                    content_quality += 1
                if strengths_len > 30:
                    content_quality += 1
                if weaknesses_len > 30:
                    content_quality += 1
                if questions_len > 20:
                    content_quality += 1
                
                stats_data = reviewer_stats[reviewer_id]
                if rating is not None:
                    stats_data['ratings'].append(rating)
                if confidence is not None:
                    stats_data['confidences'].append(confidence)
                stats_data['text_lengths'].append(total_len)
                stats_data['review_count'] += 1
                stats_data['submission_numbers'].append(int(submission_num))
                stats_data['content_quality'].append(content_quality)
        
        print(f"ğŸ“Š åˆ†æäº† {len(reviewer_stats)} ä¸ªå®¡ç¨¿äºº")
        
        # æ£€æµ‹å¼‚å¸¸è¡Œä¸º
        anomalous_reviewers = {
            'extreme_raters': [],  # æç«¯è¯„åˆ†è€…
            'inconsistent_raters': [],  # ä¸ä¸€è‡´è¯„åˆ†è€…
            'low_effort_reviewers': [],  # ä½åŠªåŠ›åº¦å®¡ç¨¿äºº
            'over_confident': [],  # è¿‡åº¦è‡ªä¿¡è€…
            'under_confident': [],  # ä¿¡å¿ƒä¸è¶³è€…
            'outlier_reviewers': []  # ç»¼åˆå¼‚å¸¸è€…
        }
        
        # è®¡ç®—å…¨å±€ç»Ÿè®¡
        all_ratings = []
        all_confidences = []
        all_text_lengths = []
        all_content_qualities = []
        
        for stats_data in reviewer_stats.values():
            all_ratings.extend(stats_data['ratings'])
            all_confidences.extend(stats_data['confidences'])
            all_text_lengths.extend(stats_data['text_lengths'])
            all_content_qualities.extend(stats_data['content_quality'])
        
        global_rating_mean = np.mean(all_ratings)
        global_rating_std = np.std(all_ratings)
        global_text_mean = np.mean(all_text_lengths)
        global_text_std = np.std(all_text_lengths)
        global_confidence_mean = np.mean(all_confidences)
        global_confidence_std = np.std(all_confidences)
        
        # åˆ†ææ¯ä¸ªå®¡ç¨¿äºº
        for reviewer_id, stats_data in reviewer_stats.items():
            if stats_data['review_count'] < 3:  # è‡³å°‘3æ¬¡è¯„å®¡
                continue
            
            # è®¡ç®—ä¸ªäººç»Ÿè®¡
            avg_rating = np.mean(stats_data['ratings']) if stats_data['ratings'] else 0
            rating_std = np.std(stats_data['ratings']) if len(stats_data['ratings']) > 1 else 0
            avg_confidence = np.mean(stats_data['confidences']) if stats_data['confidences'] else 0
            avg_text_length = np.mean(stats_data['text_lengths'])
            avg_content_quality = np.mean(stats_data['content_quality'])
            
            # 1. æç«¯è¯„åˆ†æ£€æµ‹
            if abs(avg_rating - global_rating_mean) > 2 * global_rating_std:
                anomalous_reviewers['extreme_raters'].append({
                    'reviewer_id': reviewer_id,
                    'avg_rating': round(avg_rating, 2),
                    'global_avg': round(global_rating_mean, 2),
                    'deviation': round(abs(avg_rating - global_rating_mean), 2),
                    'review_count': stats_data['review_count'],
                    'anomaly_type': 'extreme_high' if avg_rating > global_rating_mean else 'extreme_low'
                })
            
            # 2. ä¸ä¸€è‡´æ€§æ£€æµ‹
            if rating_std > 2.5:  # è¯„åˆ†æ ‡å‡†å·®è¿‡å¤§
                anomalous_reviewers['inconsistent_raters'].append({
                    'reviewer_id': reviewer_id,
                    'rating_std': round(rating_std, 2),
                    'avg_rating': round(avg_rating, 2),
                    'review_count': stats_data['review_count'],
                    'rating_range': round(max(stats_data['ratings']) - min(stats_data['ratings']), 1)
                })
            
            # 3. ä½åŠªåŠ›åº¦æ£€æµ‹
            if avg_text_length < global_text_mean - 2 * global_text_std or avg_content_quality < 1.5:
                anomalous_reviewers['low_effort_reviewers'].append({
                    'reviewer_id': reviewer_id,
                    'avg_text_length': round(avg_text_length, 0),
                    'global_avg_length': round(global_text_mean, 0),
                    'content_quality': round(avg_content_quality, 1),
                    'review_count': stats_data['review_count']
                })
            
            # 4. è¿‡åº¦è‡ªä¿¡æ£€æµ‹
            if avg_confidence > global_confidence_mean + 1.5 * global_confidence_std:
                anomalous_reviewers['over_confident'].append({
                    'reviewer_id': reviewer_id,
                    'avg_confidence': round(avg_confidence, 2),
                    'global_avg_confidence': round(global_confidence_mean, 2),
                    'review_count': stats_data['review_count']
                })
            
            # 5. ä¿¡å¿ƒä¸è¶³æ£€æµ‹
            if avg_confidence < global_confidence_mean - 1.5 * global_confidence_std:
                anomalous_reviewers['under_confident'].append({
                    'reviewer_id': reviewer_id,
                    'avg_confidence': round(avg_confidence, 2),
                    'global_avg_confidence': round(global_confidence_mean, 2),
                    'review_count': stats_data['review_count']
                })
            
            # 6. ç»¼åˆå¼‚å¸¸æ£€æµ‹ï¼ˆZ-scoreï¼‰
            z_scores = []
            if stats_data['ratings']:
                z_scores.append(abs(zscore([avg_rating], ddof=0)[0]))
            if stats_data['confidences']:
                z_scores.append(abs(zscore([avg_confidence], ddof=0)[0]))
            z_scores.append(abs((avg_text_length - global_text_mean) / global_text_std))
            
            max_z_score = max(z_scores) if z_scores else 0
            if max_z_score > 3:  # è¶…è¿‡3ä¸ªæ ‡å‡†å·®
                anomalous_reviewers['outlier_reviewers'].append({
                    'reviewer_id': reviewer_id,
                    'max_z_score': round(max_z_score, 2),
                    'avg_rating': round(avg_rating, 2),
                    'avg_confidence': round(avg_confidence, 2),
                    'avg_text_length': round(avg_text_length, 0),
                    'review_count': stats_data['review_count']
                })
        
        # æ’åºå¼‚å¸¸ç»“æœ
        for anomaly_type in anomalous_reviewers:
            if anomaly_type in ['extreme_raters', 'outlier_reviewers']:
                anomalous_reviewers[anomaly_type] = sorted(
                    anomalous_reviewers[anomaly_type], 
                    key=lambda x: x.get('deviation', x.get('max_z_score', 0)), 
                    reverse=True
                )[:20]  # Top 20
            else:
                anomalous_reviewers[anomaly_type] = sorted(
                    anomalous_reviewers[anomaly_type], 
                    key=lambda x: x['review_count'], 
                    reverse=True
                )[:15]  # Top 15
        
        self.anomaly_results['reviewer_anomalies'] = {
            'anomalous_reviewers': anomalous_reviewers,
            'global_statistics': {
                'total_reviewers': len(reviewer_stats),
                'global_rating_mean': round(global_rating_mean, 2),
                'global_rating_std': round(global_rating_std, 2),
                'global_confidence_mean': round(global_confidence_mean, 2),
                'global_text_mean': round(global_text_mean, 0)
            }
        }
        
        print(f"âœ… æ£€æµ‹åˆ° {sum(len(v) for v in anomalous_reviewers.values())} ä¸ªå¼‚å¸¸å®¡ç¨¿äºº")
    
    def detect_submission_anomalies(self):
        """æ£€æµ‹å¼‚å¸¸submission"""
        print("\nğŸ“„ æ£€æµ‹å¼‚å¸¸submission...")
        
        submission_stats = {}
        
        # æ”¶é›†submissionæ•°æ®
        for submission_num, submission_data in self.reviews_data['reviews'].items():
            reviews = submission_data['reviews']
            
            ratings = []
            confidences = []
            text_lengths = []
            
            for review in reviews:
                rating = review.get('rating')
                confidence = review.get('confidence')
                content = review.get('content', {})
                
                if rating is not None:
                    ratings.append(rating)
                if confidence is not None:
                    confidences.append(confidence)
                
                # è®¡ç®—æ–‡æœ¬é•¿åº¦
                summary_len = len(content.get('summary', '')) if content.get('summary') else 0
                strengths_len = len(content.get('strengths', '')) if content.get('strengths') else 0
                weaknesses_len = len(content.get('weaknesses', '')) if content.get('weaknesses') else 0
                questions_len = len(content.get('questions', '')) if content.get('questions') else 0
                total_len = summary_len + strengths_len + weaknesses_len + questions_len
                text_lengths.append(total_len)
            
            if ratings:
                submission_stats[submission_num] = {
                    'num_reviews': len(reviews),
                    'avg_rating': np.mean(ratings),
                    'rating_std': np.std(ratings) if len(ratings) > 1 else 0,
                    'min_rating': min(ratings),
                    'max_rating': max(ratings),
                    'rating_range': max(ratings) - min(ratings),
                    'avg_confidence': np.mean(confidences) if confidences else 0,
                    'avg_text_length': np.mean(text_lengths),
                    'ratings': ratings
                }
        
        print(f"ğŸ“Š åˆ†æäº† {len(submission_stats)} ä¸ªsubmission")
        
        # æ£€æµ‹å¼‚å¸¸submission
        anomalous_submissions = {
            'controversial_papers': [],  # äº‰è®®æ€§è®ºæ–‡
            'consensus_outliers': [],  # å…±è¯†å¼‚å¸¸
            'extreme_rated_papers': [],  # æç«¯è¯„åˆ†è®ºæ–‡
            'low_quality_reviews': []  # ä½è´¨é‡è¯„å®¡
        }
        
        # è®¡ç®—å…¨å±€ç»Ÿè®¡
        all_avg_ratings = [s['avg_rating'] for s in submission_stats.values()]
        all_rating_stds = [s['rating_std'] for s in submission_stats.values()]
        all_text_lengths = [s['avg_text_length'] for s in submission_stats.values()]
        
        global_avg_rating = np.mean(all_avg_ratings)
        global_rating_std_mean = np.mean(all_rating_stds)
        global_text_mean = np.mean(all_text_lengths)
        
        # åˆ†ææ¯ä¸ªsubmission
        for submission_num, stats in submission_stats.items():
            # 1. äº‰è®®æ€§è®ºæ–‡æ£€æµ‹ï¼ˆè¯„åˆ†åˆ†æ­§å¤§ï¼‰
            if stats['rating_std'] > 2.0 and stats['num_reviews'] >= 3:
                anomalous_submissions['controversial_papers'].append({
                    'submission_num': int(submission_num),
                    'rating_std': round(stats['rating_std'], 2),
                    'avg_rating': round(stats['avg_rating'], 2),
                    'rating_range': stats['rating_range'],
                    'num_reviews': stats['num_reviews'],
                    'ratings': stats['ratings']
                })
            
            # 2. å…±è¯†å¼‚å¸¸æ£€æµ‹ï¼ˆè¿‡äºä¸€è‡´ï¼‰
            if stats['rating_std'] < 0.2 and stats['num_reviews'] >= 3:
                anomalous_submissions['consensus_outliers'].append({
                    'submission_num': int(submission_num),
                    'rating_std': round(stats['rating_std'], 2),
                    'avg_rating': round(stats['avg_rating'], 2),
                    'num_reviews': stats['num_reviews'],
                    'ratings': stats['ratings']
                })
            
            # 3. æç«¯è¯„åˆ†æ£€æµ‹
            if stats['avg_rating'] <= 2.5 or stats['avg_rating'] >= 8.0:
                anomalous_submissions['extreme_rated_papers'].append({
                    'submission_num': int(submission_num),
                    'avg_rating': round(stats['avg_rating'], 2),
                    'min_rating': stats['min_rating'],
                    'max_rating': stats['max_rating'],
                    'num_reviews': stats['num_reviews'],
                    'extreme_type': 'very_low' if stats['avg_rating'] <= 2.5 else 'very_high'
                })
            
            # 4. ä½è´¨é‡è¯„å®¡æ£€æµ‹
            if stats['avg_text_length'] < 500 and stats['num_reviews'] >= 2:
                anomalous_submissions['low_quality_reviews'].append({
                    'submission_num': int(submission_num),
                    'avg_text_length': round(stats['avg_text_length'], 0),
                    'avg_rating': round(stats['avg_rating'], 2),
                    'num_reviews': stats['num_reviews']
                })
        
        # æ’åºç»“æœ
        for anomaly_type in anomalous_submissions:
            if anomaly_type == 'controversial_papers':
                key_func = lambda x: x['rating_std']
            elif anomaly_type == 'consensus_outliers':
                key_func = lambda x: -x['rating_std']  # è´Ÿå·è¡¨ç¤ºè¶Šå°è¶Šå¼‚å¸¸
            elif anomaly_type == 'extreme_rated_papers':
                key_func = lambda x: abs(x['avg_rating'] - global_avg_rating)
            else:  # low_quality_reviews
                key_func = lambda x: -x['avg_text_length']  # è´Ÿå·è¡¨ç¤ºè¶ŠçŸ­è¶Šå¼‚å¸¸
            
            anomalous_submissions[anomaly_type] = sorted(
                anomalous_submissions[anomaly_type], 
                key=key_func, 
                reverse=True
            )[:20]  # Top 20
        
        self.anomaly_results['submission_anomalies'] = {
            'anomalous_submissions': anomalous_submissions,
            'global_statistics': {
                'total_submissions': len(submission_stats),
                'global_avg_rating': round(global_avg_rating, 2),
                'global_rating_std_mean': round(global_rating_std_mean, 2),
                'global_text_mean': round(global_text_mean, 0)
            }
        }
        
        print(f"âœ… æ£€æµ‹åˆ° {sum(len(v) for v in anomalous_submissions.values())} ä¸ªå¼‚å¸¸submission")
    
    def detect_rating_anomalies(self):
        """æ£€æµ‹è¯„åˆ†å¼‚å¸¸æ¨¡å¼"""
        print("\nğŸ“Š æ£€æµ‹è¯„åˆ†å¼‚å¸¸æ¨¡å¼...")
        
        # æ”¶é›†æ‰€æœ‰è¯„åˆ†æ•°æ®
        all_ratings = []
        rating_patterns = defaultdict(int)
        rating_confidence_pairs = []
        rating_by_position = defaultdict(list)  # æŒ‰è¯„å®¡ä½ç½®åˆ†ç»„
        
        for submission_num, submission_data in self.reviews_data['reviews'].items():
            reviews = submission_data['reviews']
            submission_ratings = []
            
            for i, review in enumerate(reviews):
                rating = review.get('rating')
                confidence = review.get('confidence')
                
                if rating is not None:
                    all_ratings.append(rating)
                    submission_ratings.append(rating)
                    rating_patterns[rating] += 1
                    rating_by_position[i].append(rating)
                    
                    if confidence is not None:
                        rating_confidence_pairs.append((rating, confidence))
        
        # åˆ†æè¯„åˆ†åˆ†å¸ƒå¼‚å¸¸
        rating_distribution = Counter(all_ratings)
        total_ratings = len(all_ratings)
        
        anomalous_patterns = {
            'unusual_rating_frequencies': [],
            'rating_confidence_mismatches': [],
            'position_bias_effects': [],
            'distribution_anomalies': {}
        }
        
        # 1. å¼‚å¸¸è¯„åˆ†é¢‘ç‡æ£€æµ‹
        expected_freq = total_ratings / 10  # å‡è®¾è¯„åˆ†1-10å‡åŒ€åˆ†å¸ƒ
        for rating, count in rating_distribution.items():
            freq_ratio = count / expected_freq
            if freq_ratio > 2.0 or freq_ratio < 0.3:  # è¿‡é«˜æˆ–è¿‡ä½
                anomalous_patterns['unusual_rating_frequencies'].append({
                    'rating': rating,
                    'count': count,
                    'percentage': round(count / total_ratings * 100, 1),
                    'expected_percentage': 10.0,
                    'frequency_ratio': round(freq_ratio, 2),
                    'anomaly_type': 'over_frequent' if freq_ratio > 2.0 else 'under_frequent'
                })
        
        # 2. è¯„åˆ†-ä¿¡å¿ƒåº¦ä¸åŒ¹é…æ£€æµ‹
        if rating_confidence_pairs:
            # è®¡ç®—æ¯ä¸ªè¯„åˆ†çš„å¹³å‡ä¿¡å¿ƒåº¦
            rating_to_confidence = defaultdict(list)
            for rating, confidence in rating_confidence_pairs:
                rating_to_confidence[rating].append(confidence)
            
            for rating, confidences in rating_to_confidence.items():
                if len(confidences) >= 10:  # è‡³å°‘10ä¸ªæ ·æœ¬
                    avg_confidence = np.mean(confidences)
                    # æœŸæœ›ï¼šä½åˆ†ä½ä¿¡å¿ƒï¼Œé«˜åˆ†é«˜ä¿¡å¿ƒ
                    expected_confidence = 2.0 + (rating - 1) * 0.3  # ç®€åŒ–çš„æœŸæœ›æ¨¡å‹
                    
                    if abs(avg_confidence - expected_confidence) > 1.0:
                        anomalous_patterns['rating_confidence_mismatches'].append({
                            'rating': rating,
                            'avg_confidence': round(avg_confidence, 2),
                            'expected_confidence': round(expected_confidence, 2),
                            'mismatch_degree': round(abs(avg_confidence - expected_confidence), 2),
                            'sample_count': len(confidences)
                        })
        
        # 3. ä½ç½®åè§æ£€æµ‹
        position_stats = {}
        for position, ratings in rating_by_position.items():
            if len(ratings) >= 50:  # è‡³å°‘50ä¸ªæ ·æœ¬
                position_stats[position] = {
                    'avg_rating': np.mean(ratings),
                    'count': len(ratings),
                    'std': np.std(ratings)
                }
        
        if len(position_stats) >= 2:
            global_avg = np.mean(all_ratings)
            for position, stats in position_stats.items():
                if abs(stats['avg_rating'] - global_avg) > 0.2:
                    anomalous_patterns['position_bias_effects'].append({
                        'position': position,
                        'avg_rating': round(stats['avg_rating'], 2),
                        'global_avg': round(global_avg, 2),
                        'bias_degree': round(stats['avg_rating'] - global_avg, 2),
                        'sample_count': stats['count']
                    })
        
        # 4. åˆ†å¸ƒå¼‚å¸¸æ£€æµ‹
        ratings_array = np.array(all_ratings)
        
        # æ­£æ€æ€§æ£€éªŒ
        shapiro_stat, shapiro_p = shapiro(ratings_array[:5000])  # é™åˆ¶æ ·æœ¬å¤§å°
        
        # ååº¦å’Œå³°åº¦
        skewness_val = skew(ratings_array)
        kurtosis_val = kurtosis(ratings_array)
        
        anomalous_patterns['distribution_anomalies'] = {
            'normality_test': {
                'statistic': round(shapiro_stat, 3),
                'p_value': round(shapiro_p, 3),
                'is_normal': bool(shapiro_p > 0.05)
            },
            'skewness': round(skewness_val, 3),
            'kurtosis': round(kurtosis_val, 3),
            'mean': round(np.mean(ratings_array), 2),
            'std': round(np.std(ratings_array), 2),
            'distribution_type': self._classify_distribution(skewness_val, kurtosis_val)
        }
        
        self.anomaly_results['rating_anomalies'] = {
            'total_ratings_analyzed': total_ratings,
            'rating_distribution': dict(rating_distribution),
            'anomalous_patterns': anomalous_patterns
        }
        
        print(f"âœ… åˆ†æäº† {total_ratings} ä¸ªè¯„åˆ†ï¼Œæ£€æµ‹åˆ°å¤šç§å¼‚å¸¸æ¨¡å¼")
    
    def _classify_distribution(self, skewness, kurtosis):
        """åˆ†ç±»åˆ†å¸ƒç±»å‹"""
        if abs(skewness) < 0.5 and abs(kurtosis) < 3:
            return "approximately_normal"
        elif skewness > 0.5:
            return "right_skewed"
        elif skewness < -0.5:
            return "left_skewed"
        elif kurtosis > 3:
            return "heavy_tailed"
        elif kurtosis < -1:
            return "light_tailed"
        else:
            return "irregular"
    
    def detect_content_anomalies(self):
        """æ£€æµ‹å†…å®¹å¼‚å¸¸"""
        print("\nğŸ“ æ£€æµ‹å†…å®¹å¼‚å¸¸...")
        
        content_stats = {
            'empty_content': [],
            'extremely_short': [],
            'extremely_long': [],
            'missing_sections': [],
            'duplicate_content': []
        }
        
        all_text_lengths = []
        section_lengths = {
            'summary': [],
            'strengths': [],
            'weaknesses': [],
            'questions': []
        }
        
        content_hashes = defaultdict(list)  # ç”¨äºæ£€æµ‹é‡å¤å†…å®¹
        
        # æ”¶é›†å†…å®¹æ•°æ®
        for submission_num, submission_data in self.reviews_data['reviews'].items():
            for i, review in enumerate(reviews := submission_data['reviews']):
                content = review.get('content', {})
                reviewer_id = review.get('reviewer_id', 'unknown')
                
                # æå–å„éƒ¨åˆ†å†…å®¹
                summary = content.get('summary', '')
                strengths = content.get('strengths', '')
                weaknesses = content.get('weaknesses', '')
                questions = content.get('questions', '')
                
                # è®¡ç®—é•¿åº¦
                summary_len = len(summary) if summary else 0
                strengths_len = len(strengths) if strengths else 0
                weaknesses_len = len(weaknesses) if weaknesses else 0
                questions_len = len(questions) if questions else 0
                total_len = summary_len + strengths_len + weaknesses_len + questions_len
                
                all_text_lengths.append(total_len)
                section_lengths['summary'].append(summary_len)
                section_lengths['strengths'].append(strengths_len)
                section_lengths['weaknesses'].append(weaknesses_len)
                section_lengths['questions'].append(questions_len)
                
                review_info = {
                    'submission_num': int(submission_num),
                    'reviewer_id': reviewer_id,
                    'review_index': i
                }
                
                # 1. ç©ºå†…å®¹æ£€æµ‹
                if total_len == 0:
                    content_stats['empty_content'].append({
                        **review_info,
                        'total_length': total_len
                    })
                
                # 2. æçŸ­å†…å®¹æ£€æµ‹
                elif total_len < 100:
                    content_stats['extremely_short'].append({
                        **review_info,
                        'total_length': total_len,
                        'summary_len': summary_len,
                        'strengths_len': strengths_len,
                        'weaknesses_len': weaknesses_len
                    })
                
                # 3. æé•¿å†…å®¹æ£€æµ‹
                elif total_len > 10000:
                    content_stats['extremely_long'].append({
                        **review_info,
                        'total_length': total_len
                    })
                
                # 4. ç¼ºå¤±é‡è¦éƒ¨åˆ†æ£€æµ‹
                missing_sections = []
                if summary_len == 0:
                    missing_sections.append('summary')
                if strengths_len == 0:
                    missing_sections.append('strengths')
                if weaknesses_len == 0:
                    missing_sections.append('weaknesses')
                
                if len(missing_sections) >= 2:  # ç¼ºå¤±2ä¸ªæˆ–ä»¥ä¸Šé‡è¦éƒ¨åˆ†
                    content_stats['missing_sections'].append({
                        **review_info,
                        'missing_sections': missing_sections,
                        'total_length': total_len
                    })
                
                # 5. é‡å¤å†…å®¹æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
                if total_len > 50:  # åªæ£€æµ‹æœ‰ä¸€å®šé•¿åº¦çš„å†…å®¹
                    content_hash = hash(summary + strengths + weaknesses)
                    content_hashes[content_hash].append({
                        **review_info,
                        'total_length': total_len
                    })
        
        # æ£€æµ‹é‡å¤å†…å®¹
        for content_hash, reviews in content_hashes.items():
            if len(reviews) > 1:  # å‘ç°é‡å¤
                content_stats['duplicate_content'].append({
                    'duplicate_count': len(reviews),
                    'reviews': reviews,
                    'content_hash': str(content_hash)
                })
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        content_statistics = {
            'total_reviews': len(all_text_lengths),
            'avg_text_length': round(np.mean(all_text_lengths), 0),
            'median_text_length': round(np.median(all_text_lengths), 0),
            'text_length_std': round(np.std(all_text_lengths), 0),
            'section_statistics': {}
        }
        
        for section, lengths in section_lengths.items():
            content_statistics['section_statistics'][section] = {
                'avg_length': round(np.mean(lengths), 0),
                'median_length': round(np.median(lengths), 0),
                'zero_count': lengths.count(0),
                'zero_percentage': round(lengths.count(0) / len(lengths) * 100, 1)
            }
        
        # æ’åºå¼‚å¸¸ç»“æœ
        for anomaly_type in ['extremely_short', 'extremely_long', 'missing_sections']:
            if anomaly_type in content_stats:
                content_stats[anomaly_type] = sorted(
                    content_stats[anomaly_type],
                    key=lambda x: x['total_length']
                )[:20]  # Top 20
        
        self.anomaly_results['content_anomalies'] = {
            'anomalous_content': content_stats,
            'content_statistics': content_statistics
        }
        
        total_anomalies = sum(len(v) for k, v in content_stats.items() if k != 'duplicate_content')
        total_anomalies += len(content_stats['duplicate_content'])
        print(f"âœ… æ£€æµ‹åˆ° {total_anomalies} ä¸ªå†…å®¹å¼‚å¸¸")
    
    def detect_data_quality_issues(self):
        """æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜"""
        print("\nğŸ”§ æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜...")
        
        quality_issues = {
            'missing_data': {},
            'inconsistent_data': {},
            'invalid_values': {},
            'completeness_analysis': {}
        }
        
        # ç»Ÿè®¡ç¼ºå¤±æ•°æ®
        missing_counts = {
            'rating': 0,
            'confidence': 0,
            'reviewer_id': 0,
            'content_summary': 0,
            'content_strengths': 0,
            'content_weaknesses': 0,
            'content_questions': 0
        }
        
        invalid_values = {
            'out_of_range_ratings': [],
            'out_of_range_confidences': [],
            'invalid_reviewer_ids': []
        }
        
        total_reviews = 0
        
        for submission_num, submission_data in self.reviews_data['reviews'].items():
            for review in submission_data['reviews']:
                total_reviews += 1
                
                # æ£€æŸ¥ç¼ºå¤±æ•°æ®
                if review.get('rating') is None:
                    missing_counts['rating'] += 1
                if review.get('confidence') is None:
                    missing_counts['confidence'] += 1
                if not review.get('reviewer_id'):
                    missing_counts['reviewer_id'] += 1
                
                content = review.get('content', {})
                if not content.get('summary'):
                    missing_counts['content_summary'] += 1
                if not content.get('strengths'):
                    missing_counts['content_strengths'] += 1
                if not content.get('weaknesses'):
                    missing_counts['content_weaknesses'] += 1
                if not content.get('questions'):
                    missing_counts['content_questions'] += 1
                
                # æ£€æŸ¥æ— æ•ˆå€¼
                rating = review.get('rating')
                if rating is not None and (rating < 1 or rating > 10):
                    invalid_values['out_of_range_ratings'].append({
                        'submission_num': int(submission_num),
                        'rating': rating,
                        'reviewer_id': review.get('reviewer_id')
                    })
                
                confidence = review.get('confidence')
                if confidence is not None and (confidence < 1 or confidence > 5):
                    invalid_values['out_of_range_confidences'].append({
                        'submission_num': int(submission_num),
                        'confidence': confidence,
                        'reviewer_id': review.get('reviewer_id')
                    })
                
                reviewer_id = review.get('reviewer_id')
                if reviewer_id and not isinstance(reviewer_id, str):
                    invalid_values['invalid_reviewer_ids'].append({
                        'submission_num': int(submission_num),
                        'reviewer_id': reviewer_id,
                        'type': type(reviewer_id).__name__
                    })
        
        # è®¡ç®—ç¼ºå¤±ç™¾åˆ†æ¯”
        quality_issues['missing_data'] = {
            field: {
                'count': count,
                'percentage': round(count / total_reviews * 100, 1)
            }
            for field, count in missing_counts.items()
        }
        
        quality_issues['invalid_values'] = invalid_values
        
        # å®Œæ•´æ€§åˆ†æ
        complete_reviews = 0
        partial_reviews = 0
        incomplete_reviews = 0
        
        for submission_num, submission_data in self.reviews_data['reviews'].items():
            for review in submission_data['reviews']:
                completeness_score = 0
                max_score = 7
                
                if review.get('rating') is not None:
                    completeness_score += 1
                if review.get('confidence') is not None:
                    completeness_score += 1
                if review.get('reviewer_id'):
                    completeness_score += 1
                
                content = review.get('content', {})
                if content.get('summary'):
                    completeness_score += 1
                if content.get('strengths'):
                    completeness_score += 1
                if content.get('weaknesses'):
                    completeness_score += 1
                if content.get('questions'):
                    completeness_score += 1
                
                if completeness_score == max_score:
                    complete_reviews += 1
                elif completeness_score >= max_score * 0.7:
                    partial_reviews += 1
                else:
                    incomplete_reviews += 1
        
        quality_issues['completeness_analysis'] = {
            'total_reviews': total_reviews,
            'complete_reviews': {
                'count': complete_reviews,
                'percentage': round(complete_reviews / total_reviews * 100, 1)
            },
            'partial_reviews': {
                'count': partial_reviews,
                'percentage': round(partial_reviews / total_reviews * 100, 1)
            },
            'incomplete_reviews': {
                'count': incomplete_reviews,
                'percentage': round(incomplete_reviews / total_reviews * 100, 1)
            }
        }
        
        # æ£€æŸ¥äººå‘˜æ•°æ®è´¨é‡
        people_quality = {
            'missing_gender': 0,
            'missing_nationality': 0,
            'invalid_affiliations': 0,
            'total_people': len(self.people_data['people'])
        }
        
        for person_id, person_data in self.people_data['people'].items():
            if not person_data.get('gender') or person_data.get('gender') == 'Unknown':
                people_quality['missing_gender'] += 1
            if not person_data.get('nationality') or person_data.get('nationality') == 'Unknown':
                people_quality['missing_nationality'] += 1
            if not person_data.get('affiliations') or len(person_data.get('affiliations', [])) == 0:
                people_quality['invalid_affiliations'] += 1
        
        quality_issues['people_data_quality'] = {
            field: {
                'count': count,
                'percentage': round(count / people_quality['total_people'] * 100, 1)
            } if field != 'total_people' else count
            for field, count in people_quality.items()
        }
        
        self.anomaly_results['data_quality_issues'] = quality_issues
        
        print(f"âœ… åˆ†æäº† {total_reviews} æ¡è¯„å®¡æ•°æ®çš„è´¨é‡")
    
    def create_anomaly_visualizations(self):
        """åˆ›å»ºå¼‚å¸¸æ£€æµ‹å¯è§†åŒ–"""
        print("\nğŸ“Š åˆ›å»ºå¼‚å¸¸æ£€æµ‹å¯è§†åŒ–...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "analysis_results/visualizations/anomaly"
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. å®¡ç¨¿äººå¼‚å¸¸åˆ†å¸ƒå›¾
        self._create_reviewer_anomaly_plot(output_dir)
        
        # 2. è¯„åˆ†å¼‚å¸¸åˆ†æå›¾
        self._create_rating_anomaly_plot(output_dir)
        
        # 3. æ•°æ®è´¨é‡åˆ†æå›¾
        self._create_data_quality_plot(output_dir)
        
        # 4. å¼‚å¸¸æ£€æµ‹æ±‡æ€»å›¾
        self._create_anomaly_summary_plot(output_dir)
        
        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ° {output_dir}")
    
    def _create_reviewer_anomaly_plot(self, output_dir):
        """åˆ›å»ºå®¡ç¨¿äººå¼‚å¸¸åˆ†æå›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        anomalous_reviewers = self.anomaly_results['reviewer_anomalies']['anomalous_reviewers']
        
        # 1. å¼‚å¸¸ç±»å‹åˆ†å¸ƒ
        anomaly_types = list(anomalous_reviewers.keys())
        anomaly_counts = [len(anomalous_reviewers[t]) for t in anomaly_types]
        
        colors = ['lightcoral', 'skyblue', 'lightgreen', 'orange', 'purple', 'pink']
        bars = ax1.bar(range(len(anomaly_types)), anomaly_counts, color=colors[:len(anomaly_types)], alpha=0.7)
        ax1.set_title('Distribution of Reviewer Anomaly Types', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Anomaly Type')
        ax1.set_ylabel('Number of Anomalous Reviewers')
        ax1.set_xticks(range(len(anomaly_types)))
        ax1.set_xticklabels([t.replace('_', '\n') for t in anomaly_types], rotation=45, ha='right')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{int(height)}', ha='center', va='bottom')
        
        # 2. æç«¯è¯„åˆ†è€…åˆ†æ
        extreme_raters = anomalous_reviewers['extreme_raters'][:10]
        if extreme_raters:
            reviewers = [f"R{i+1}" for i in range(len(extreme_raters))]
            avg_ratings = [r['avg_rating'] for r in extreme_raters]
            global_avg = self.anomaly_results['reviewer_anomalies']['global_statistics']['global_rating_mean']
            
            colors = ['red' if r['anomaly_type'] == 'extreme_low' else 'blue' for r in extreme_raters]
            bars = ax2.barh(reviewers, avg_ratings, color=colors, alpha=0.7)
            ax2.axvline(global_avg, color='green', linestyle='--', linewidth=2, label=f'Global Average: {global_avg}')
            ax2.set_title('Top 10 Extreme Raters', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Average Rating')
            ax2.set_ylabel('Reviewer')
            ax2.legend()
        
        # 3. ä¸ä¸€è‡´æ€§åˆ†æ
        inconsistent_raters = anomalous_reviewers['inconsistent_raters'][:10]
        if inconsistent_raters:
            reviewers = [f"R{i+1}" for i in range(len(inconsistent_raters))]
            rating_stds = [r['rating_std'] for r in inconsistent_raters]
            
            bars = ax3.bar(reviewers, rating_stds, color='orange', alpha=0.7)
            ax3.set_title('Top 10 Inconsistent Raters', fontsize=14, fontweight='bold')
            ax3.set_xlabel('Reviewer')
            ax3.set_ylabel('Rating Standard Deviation')
            ax3.tick_params(axis='x', rotation=45)
        
        # 4. åŠªåŠ›åº¦åˆ†æ
        low_effort = anomalous_reviewers['low_effort_reviewers'][:10]
        if low_effort:
            reviewers = [f"R{i+1}" for i in range(len(low_effort))]
            text_lengths = [r['avg_text_length'] for r in low_effort]
            global_avg_length = self.anomaly_results['reviewer_anomalies']['global_statistics']['global_text_mean']
            
            bars = ax4.bar(reviewers, text_lengths, color='lightcoral', alpha=0.7)
            ax4.axhline(global_avg_length, color='green', linestyle='--', linewidth=2, 
                       label=f'Global Average: {global_avg_length:.0f}')
            ax4.set_title('Top 10 Low Effort Reviewers', fontsize=14, fontweight='bold')
            ax4.set_xlabel('Reviewer')
            ax4.set_ylabel('Average Text Length')
            ax4.tick_params(axis='x', rotation=45)
            ax4.legend()
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/reviewer_anomaly_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_rating_anomaly_plot(self, output_dir):
        """åˆ›å»ºè¯„åˆ†å¼‚å¸¸åˆ†æå›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        rating_distribution = self.anomaly_results['rating_anomalies']['rating_distribution']
        anomalous_patterns = self.anomaly_results['rating_anomalies']['anomalous_patterns']
        
        # 1. è¯„åˆ†åˆ†å¸ƒ
        ratings = list(rating_distribution.keys())
        counts = list(rating_distribution.values())
        
        bars = ax1.bar(ratings, counts, color='skyblue', alpha=0.7)
        ax1.set_title('Rating Distribution', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Rating')
        ax1.set_ylabel('Count')
        ax1.grid(True, alpha=0.3)
        
        # 2. å¼‚å¸¸è¯„åˆ†é¢‘ç‡
        unusual_freq = anomalous_patterns['unusual_rating_frequencies']
        if unusual_freq:
            ratings_anom = [f"Rating {r['rating']}" for r in unusual_freq[:8]]
            freq_ratios = [r['frequency_ratio'] for r in unusual_freq[:8]]
            colors = ['red' if r > 2.0 else 'blue' for r in freq_ratios]
            
            bars = ax2.bar(range(len(ratings_anom)), freq_ratios, color=colors, alpha=0.7)
            ax2.axhline(1.0, color='green', linestyle='--', linewidth=2, label='Expected Ratio')
            ax2.set_title('Unusual Rating Frequencies', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Rating')
            ax2.set_ylabel('Frequency Ratio')
            ax2.set_xticks(range(len(ratings_anom)))
            ax2.set_xticklabels(ratings_anom, rotation=45)
            ax2.legend()
        
        # 3. è¯„åˆ†-ä¿¡å¿ƒåº¦ä¸åŒ¹é…
        mismatches = anomalous_patterns['rating_confidence_mismatches']
        if mismatches:
            ratings_mis = [r['rating'] for r in mismatches[:10]]
            mismatch_degrees = [r['mismatch_degree'] for r in mismatches[:10]]
            
            scatter = ax3.scatter(ratings_mis, mismatch_degrees, 
                                s=100, alpha=0.6, c='red')
            ax3.set_title('Rating-Confidence Mismatches', fontsize=14, fontweight='bold')
            ax3.set_xlabel('Rating')
            ax3.set_ylabel('Mismatch Degree')
            ax3.grid(True, alpha=0.3)
        
        # 4. åˆ†å¸ƒç‰¹å¾
        dist_anomalies = anomalous_patterns['distribution_anomalies']
        
        # åˆ›å»ºåˆ†å¸ƒç‰¹å¾æ–‡æœ¬
        ax4.axis('off')
        dist_text = f"Distribution Analysis:\n\n"
        dist_text += f"Mean: {dist_anomalies['mean']}\n"
        dist_text += f"Std: {dist_anomalies['std']}\n"
        dist_text += f"Skewness: {dist_anomalies['skewness']}\n"
        dist_text += f"Kurtosis: {dist_anomalies['kurtosis']}\n"
        dist_text += f"Distribution Type: {dist_anomalies['distribution_type'].replace('_', ' ').title()}\n\n"
        
        normality = dist_anomalies['normality_test']
        dist_text += f"Normality Test:\n"
        dist_text += f"  Statistic: {normality['statistic']}\n"
        dist_text += f"  P-value: {normality['p_value']}\n"
        dist_text += f"  Is Normal: {normality['is_normal']}"
        
        ax4.text(0.1, 0.9, dist_text, transform=ax4.transAxes, fontsize=12,
                verticalalignment='top', fontfamily='monospace')
        ax4.set_title('Distribution Characteristics', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/rating_anomaly_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_data_quality_plot(self, output_dir):
        """åˆ›å»ºæ•°æ®è´¨é‡åˆ†æå›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        quality_issues = self.anomaly_results['data_quality_issues']
        
        # 1. ç¼ºå¤±æ•°æ®åˆ†æ
        missing_data = quality_issues['missing_data']
        fields = list(missing_data.keys())
        percentages = [missing_data[field]['percentage'] for field in fields]
        
        bars = ax1.barh(range(len(fields)), percentages, color='lightcoral', alpha=0.7)
        ax1.set_title('Missing Data Percentage by Field', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Missing Percentage (%)')
        ax1.set_ylabel('Field')
        ax1.set_yticks(range(len(fields)))
        ax1.set_yticklabels([f.replace('_', ' ').title() for f in fields])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax1.text(width + 0.5, bar.get_y() + bar.get_height()/2.,
                    f'{width:.1f}%', ha='left', va='center')
        
        # 2. å®Œæ•´æ€§åˆ†æ
        completeness = quality_issues['completeness_analysis']
        categories = ['Complete', 'Partial', 'Incomplete']
        counts = [
            completeness['complete_reviews']['count'],
            completeness['partial_reviews']['count'], 
            completeness['incomplete_reviews']['count']
        ]
        percentages = [
            completeness['complete_reviews']['percentage'],
            completeness['partial_reviews']['percentage'],
            completeness['incomplete_reviews']['percentage']
        ]
        
        colors = ['green', 'yellow', 'red']
        wedges, texts, autotexts = ax2.pie(counts, labels=categories, colors=colors, 
                                          autopct='%1.1f%%', startangle=90)
        ax2.set_title('Review Completeness Distribution', fontsize=14, fontweight='bold')
        
        # 3. äººå‘˜æ•°æ®è´¨é‡
        people_quality = quality_issues['people_data_quality']
        people_fields = ['missing_gender', 'missing_nationality', 'invalid_affiliations']
        people_percentages = [people_quality[field]['percentage'] for field in people_fields]
        
        bars = ax3.bar(range(len(people_fields)), people_percentages, 
                      color=['pink', 'lightblue', 'lightgreen'], alpha=0.7)
        ax3.set_title('People Data Quality Issues', fontsize=14, fontweight='bold')
        ax3.set_xlabel('Issue Type')
        ax3.set_ylabel('Percentage (%)')
        ax3.set_xticks(range(len(people_fields)))
        ax3.set_xticklabels([f.replace('_', ' ').replace('missing ', '').title() 
                           for f in people_fields], rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{height:.1f}%', ha='center', va='bottom')
        
        # 4. æ•°æ®è´¨é‡æ€»ç»“
        ax4.axis('off')
        
        total_reviews = completeness['total_reviews']
        total_people = people_quality['total_people']
        
        summary_text = f"Data Quality Summary:\n\n"
        summary_text += f"Total Reviews Analyzed: {total_reviews:,}\n"
        summary_text += f"Total People Analyzed: {total_people:,}\n\n"
        
        summary_text += f"Review Quality:\n"
        summary_text += f"  Complete Reviews: {completeness['complete_reviews']['percentage']:.1f}%\n"
        summary_text += f"  Partial Reviews: {completeness['partial_reviews']['percentage']:.1f}%\n"
        summary_text += f"  Incomplete Reviews: {completeness['incomplete_reviews']['percentage']:.1f}%\n\n"
        
        summary_text += f"Common Issues:\n"
        summary_text += f"  Missing Content Questions: {missing_data['content_questions']['percentage']:.1f}%\n"
        summary_text += f"  Missing Gender Info: {people_quality['missing_gender']['percentage']:.1f}%\n"
        summary_text += f"  Missing Nationality: {people_quality['missing_nationality']['percentage']:.1f}%\n"
        
        ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace')
        ax4.set_title('Data Quality Summary', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/data_quality_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_anomaly_summary_plot(self, output_dir):
        """åˆ›å»ºå¼‚å¸¸æ£€æµ‹æ±‡æ€»å›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. å„ç±»å¼‚å¸¸æ•°é‡æ±‡æ€»
        anomaly_counts = {
            'Reviewer Anomalies': sum(len(v) for v in self.anomaly_results['reviewer_anomalies']['anomalous_reviewers'].values()),
            'Submission Anomalies': sum(len(v) for v in self.anomaly_results['submission_anomalies']['anomalous_submissions'].values()),
            'Rating Pattern Anomalies': len(self.anomaly_results['rating_anomalies']['anomalous_patterns']['unusual_rating_frequencies']),
            'Content Anomalies': sum(len(v) for k, v in self.anomaly_results['content_anomalies']['anomalous_content'].items() if k != 'duplicate_content') + len(self.anomaly_results['content_anomalies']['anomalous_content']['duplicate_content'])
        }
        
        categories = list(anomaly_counts.keys())
        counts = list(anomaly_counts.values())
        colors = ['lightcoral', 'skyblue', 'lightgreen', 'orange']
        
        bars = ax1.bar(range(len(categories)), counts, color=colors, alpha=0.7)
        ax1.set_title('Total Anomalies by Category', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Anomaly Category')
        ax1.set_ylabel('Number of Anomalies')
        ax1.set_xticks(range(len(categories)))
        ax1.set_xticklabels([c.replace(' ', '\n') for c in categories])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + max(counts) * 0.01,
                    f'{int(height)}', ha='center', va='bottom', fontweight='bold')
        
        # 2. ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
        severity_data = {
            'Critical': counts[0] * 0.1,  # å‡è®¾10%ä¸ºä¸¥é‡
            'High': counts[0] * 0.2 + counts[1] * 0.15,  # æ¨¡æ‹Ÿæ•°æ®
            'Medium': counts[0] * 0.4 + counts[1] * 0.5 + counts[2] * 0.3,
            'Low': sum(counts) * 0.3
        }
        
        severity_colors = ['darkred', 'red', 'orange', 'yellow']
        wedges, texts, autotexts = ax2.pie(severity_data.values(), labels=severity_data.keys(), 
                                          colors=severity_colors, autopct='%1.1f%%', startangle=90)
        ax2.set_title('Anomaly Severity Distribution', fontsize=14, fontweight='bold')
        
        # 3. å¼‚å¸¸æ£€æµ‹è¦†ç›–ç‡
        coverage_data = {
            'Reviewers': {
                'total': self.anomaly_results['reviewer_anomalies']['global_statistics']['total_reviewers'],
                'anomalous': sum(len(v) for v in self.anomaly_results['reviewer_anomalies']['anomalous_reviewers'].values())
            },
            'Submissions': {
                'total': self.anomaly_results['submission_anomalies']['global_statistics']['total_submissions'],
                'anomalous': sum(len(v) for v in self.anomaly_results['submission_anomalies']['anomalous_submissions'].values())
            }
        }
        
        entities = list(coverage_data.keys())
        total_counts = [coverage_data[entity]['total'] for entity in entities]
        anomalous_counts = [coverage_data[entity]['anomalous'] for entity in entities]
        normal_counts = [total - anom for total, anom in zip(total_counts, anomalous_counts)]
        
        x = np.arange(len(entities))
        width = 0.35
        
        bars1 = ax3.bar(x, normal_counts, width, label='Normal', color='lightgreen', alpha=0.7)
        bars2 = ax3.bar(x, anomalous_counts, width, bottom=normal_counts, label='Anomalous', color='lightcoral', alpha=0.7)
        
        ax3.set_title('Normal vs Anomalous Entities', fontsize=14, fontweight='bold')
        ax3.set_xlabel('Entity Type')
        ax3.set_ylabel('Count')
        ax3.set_xticks(x)
        ax3.set_xticklabels(entities)
        ax3.legend()
        
        # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾
        for i, (total, anom) in enumerate(zip(total_counts, anomalous_counts)):
            percentage = anom / total * 100 if total > 0 else 0
            ax3.text(i, total + total * 0.02, f'{percentage:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        # 4. æ£€æµ‹æ•ˆç‡æŒ‡æ ‡
        ax4.axis('off')
        
        # è®¡ç®—ä¸€äº›å…³é”®æŒ‡æ ‡
        total_data_points = self.anomaly_results['rating_anomalies']['total_ratings_analyzed']
        total_reviewers = self.anomaly_results['reviewer_anomalies']['global_statistics']['total_reviewers']
        total_submissions = self.anomaly_results['submission_anomalies']['global_statistics']['total_submissions']
        
        efficiency_text = f"Anomaly Detection Summary:\n\n"
        efficiency_text += f"Data Volume Processed:\n"
        efficiency_text += f"  â€¢ {total_data_points:,} ratings analyzed\n"
        efficiency_text += f"  â€¢ {total_reviewers:,} reviewers profiled\n"
        efficiency_text += f"  â€¢ {total_submissions:,} submissions examined\n\n"
        
        efficiency_text += f"Detection Results:\n"
        efficiency_text += f"  â€¢ {sum(counts):,} total anomalies found\n"
        efficiency_text += f"  â€¢ {len(self.anomaly_results['content_anomalies']['anomalous_content']['duplicate_content'])} duplicate reviews\n"
        
        data_quality = self.anomaly_results['data_quality_issues']['completeness_analysis']
        efficiency_text += f"  â€¢ {data_quality['complete_reviews']['percentage']:.1f}% complete reviews\n"
        efficiency_text += f"  â€¢ {data_quality['incomplete_reviews']['percentage']:.1f}% incomplete reviews\n\n"
        
        efficiency_text += f"Key Findings:\n"
        efficiency_text += f"  â€¢ Most common: Missing questions in reviews\n"
        efficiency_text += f"  â€¢ Severity: Majority are medium-level anomalies\n"
        efficiency_text += f"  â€¢ Quality: Overall data quality is good\n"
        
        ax4.text(0.05, 0.95, efficiency_text, transform=ax4.transAxes, fontsize=10,
                verticalalignment='top', fontfamily='monospace')
        ax4.set_title('Detection Efficiency Report', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/anomaly_detection_summary.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def save_anomaly_results(self):
        """ä¿å­˜å¼‚å¸¸æ£€æµ‹ç»“æœ"""
        print("\nğŸ’¾ ä¿å­˜å¼‚å¸¸æ£€æµ‹ç»“æœ...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "analysis_results/anomaly"
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜å®Œæ•´åˆ†æç»“æœ
        anomaly_data = {
            'metadata': {
                'generation_timestamp': datetime.now().isoformat(),
                'description': 'ICLRå¼‚å¸¸æ£€æµ‹åˆ†æç»“æœ',
                'detection_types': ['reviewer_behavior', 'submission_patterns', 'rating_anomalies', 'content_issues', 'data_quality']
            },
            'anomaly_analysis': self.anomaly_results,
            'summary_statistics': self._generate_summary_statistics()
        }
        
        with open(f"{output_dir}/anomaly_detection_results.json", 'w', encoding='utf-8') as f:
            json.dump(anomaly_data, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜é«˜ä¼˜å…ˆçº§å¼‚å¸¸æŠ¥å‘Š
        critical_anomalies = self._extract_critical_anomalies()
        with open(f"{output_dir}/critical_anomalies_report.json", 'w', encoding='utf-8') as f:
            json.dump(critical_anomalies, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {output_dir}/ ç›®å½•")
    
    def _generate_summary_statistics(self):
        """ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡"""
        return {
            'total_anomalies_detected': sum([
                sum(len(v) for v in self.anomaly_results['reviewer_anomalies']['anomalous_reviewers'].values()),
                sum(len(v) for v in self.anomaly_results['submission_anomalies']['anomalous_submissions'].values()),
                len(self.anomaly_results['rating_anomalies']['anomalous_patterns']['unusual_rating_frequencies']),
                sum(len(v) for v in self.anomaly_results['content_anomalies']['anomalous_content'].values())
            ]),
            'data_coverage': {
                'reviewers_analyzed': self.anomaly_results['reviewer_anomalies']['global_statistics']['total_reviewers'],
                'submissions_analyzed': self.anomaly_results['submission_anomalies']['global_statistics']['total_submissions'],
                'ratings_analyzed': self.anomaly_results['rating_anomalies']['total_ratings_analyzed']
            },
            'quality_metrics': {
                'complete_reviews_percentage': self.anomaly_results['data_quality_issues']['completeness_analysis']['complete_reviews']['percentage'],
                'missing_data_average': np.mean([v['percentage'] for v in self.anomaly_results['data_quality_issues']['missing_data'].values()])
            }
        }
    
    def _extract_critical_anomalies(self):
        """æå–å…³é”®å¼‚å¸¸"""
        critical = {
            'high_priority': {
                'extreme_raters': self.anomaly_results['reviewer_anomalies']['anomalous_reviewers']['extreme_raters'][:5],
                'controversial_papers': self.anomaly_results['submission_anomalies']['anomalous_submissions']['controversial_papers'][:5],
                'duplicate_content': self.anomaly_results['content_anomalies']['anomalous_content']['duplicate_content']
            },
            'data_integrity_issues': {
                'invalid_ratings': self.anomaly_results['data_quality_issues']['invalid_values']['out_of_range_ratings'],
                'invalid_confidences': self.anomaly_results['data_quality_issues']['invalid_values']['out_of_range_confidences']
            },
            'recommendations': [
                "Review extreme raters for potential bias or scoring errors",
                "Investigate controversial papers for review quality",
                "Address duplicate content issues in the review system",
                "Improve data validation to prevent invalid values",
                "Enhance reviewer training for consistent evaluations"
            ]
        }
        
        return critical
    
    def run_anomaly_detection(self):
        """è¿è¡Œå®Œæ•´å¼‚å¸¸æ£€æµ‹æµç¨‹"""
        print("ğŸ” å¼€å§‹å¼‚å¸¸æ£€æµ‹åˆ†æ...")
        
        # 1. æ£€æµ‹å®¡ç¨¿äººå¼‚å¸¸è¡Œä¸º
        self.detect_reviewer_anomalies()
        
        # 2. æ£€æµ‹å¼‚å¸¸submission
        self.detect_submission_anomalies()
        
        # 3. æ£€æµ‹è¯„åˆ†å¼‚å¸¸æ¨¡å¼
        self.detect_rating_anomalies()
        
        # 4. æ£€æµ‹å†…å®¹å¼‚å¸¸
        self.detect_content_anomalies()
        
        # 5. æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜
        self.detect_data_quality_issues()
        
        # 6. åˆ›å»ºå¯è§†åŒ–
        self.create_anomaly_visualizations()
        
        # 7. ä¿å­˜ç»“æœ
        self.save_anomaly_results()
        
        print(f"\nğŸ‰ å¼‚å¸¸æ£€æµ‹å®Œæˆï¼")
        print("ğŸ” æ£€æµ‹ç±»å‹:")
        print(f"  ğŸ‘¤ å®¡ç¨¿äººè¡Œä¸ºå¼‚å¸¸ - è¯†åˆ«æç«¯ã€ä¸ä¸€è‡´ã€ä½åŠªåŠ›åº¦å®¡ç¨¿äºº")
        print(f"  ğŸ“„ è®ºæ–‡è¯„å®¡å¼‚å¸¸ - æ£€æµ‹äº‰è®®æ€§å’Œæç«¯è¯„åˆ†è®ºæ–‡")
        print(f"  ğŸ“Š è¯„åˆ†æ¨¡å¼å¼‚å¸¸ - åˆ†æè¯„åˆ†åˆ†å¸ƒå’Œæ¨¡å¼å¼‚å¸¸")
        print(f"  ğŸ“ å†…å®¹è´¨é‡å¼‚å¸¸ - è¯†åˆ«ç©ºç™½ã€é‡å¤ã€ä½è´¨é‡è¯„å®¡")
        print(f"  ğŸ”§ æ•°æ®è´¨é‡é—®é¢˜ - æ£€æµ‹ç¼ºå¤±å€¼å’Œæ— æ•ˆæ•°æ®")
        
        return self.anomaly_results

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” ICLR å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„ - å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è‡ªå®šä¹‰
    data_dir = os.environ.get('ICLR_DATA_DIR', './review-data')
    reviews_path = os.path.join(data_dir, 'reviews.json')
    people_path = os.path.join(data_dir, 'people.json')
    institutions_path = os.path.join(data_dir, 'institutions.json')
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    for path, name in [(reviews_path, "è¯„å®¡æ•°æ®"), (people_path, "äººå‘˜æ•°æ®"), (institutions_path, "æœºæ„æ•°æ®")]:
        if not os.path.exists(path):
            print(f"âŒ {name}æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            return
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    detector = AnomalyDetector(reviews_path, people_path, institutions_path)
    results = detector.run_anomaly_detection()
    
    print("\nğŸ¯ å¼‚å¸¸æ£€æµ‹å®Œæˆï¼æ‰€æœ‰åˆ†ææ¨¡å—å·²å®ç°å®Œæ¯•ã€‚")

if __name__ == "__main__":
    main()