#!/usr/bin/env python3
"""
ICLR åœ°åŸŸç»´åº¦åˆ†ææ¨¡å—
å®ç°å›½å®¶å­¦æœ¯ç‰¹å¾ã€è·¨å›½åˆä½œã€åœ°åŸŸåè§å’Œæ–‡åŒ–å·®å¼‚åˆ†æ
"""

import json
import numpy as np
import pandas as pd
from collections import defaultdict, Counter
from datetime import datetime
import os
from itertools import combinations
import statistics

class GeographicalAnalyzer:
    def __init__(self, reviews_data_path, people_data_path, institutions_data_path):
        """åˆå§‹åŒ–åœ°åŸŸåˆ†æå™¨"""
        print("ğŸŒ å¯åŠ¨åœ°åŸŸç»´åº¦åˆ†æ...")
        
        # åŠ è½½æ•°æ®
        with open(reviews_data_path, 'r', encoding='utf-8') as f:
            self.reviews_data = json.load(f)
            
        with open(people_data_path, 'r', encoding='utf-8') as f:
            self.people_data = json.load(f)
            
        with open(institutions_data_path, 'r', encoding='utf-8') as f:
            self.institutions_data = json.load(f)
        
        # åˆ›å»ºå›½å®¶æ˜ å°„
        self.country_data = defaultdict(lambda: {
            'reviewers': set(),
            'authors': set(),
            'institutions': set(),
            'reviews': [],
            'ratings': [],
            'confidences': [],
            'text_lengths': []
        })
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
        
    def analyze_country_characteristics(self):
        """åˆ†æå›½å®¶å­¦æœ¯ç‰¹å¾"""
        print("\nğŸŒ åˆ†æå›½å®¶å­¦æœ¯ç‰¹å¾...")
        
        # æ„å»ºå›½å®¶æ•°æ®
        reviewer_country_map = {}
        author_country_map = {}
        
        # ä»peopleæ•°æ®ä¸­æå–å›½å®¶ä¿¡æ¯
        for person_id, person_data in self.people_data['people'].items():
            nationality = person_data.get('nationality', 'Unknown')
            roles = person_data.get('roles', [])
            
            if 'reviewer' in roles:
                reviewer_country_map[person_id] = nationality
                self.country_data[nationality]['reviewers'].add(person_id)
                
            if 'author' in roles:
                author_country_map[person_id] = nationality
                self.country_data[nationality]['authors'].add(person_id)
        
        # åˆ†æè¯„å®¡è®°å½•
        processed_reviews = 0
        for submission_num, submission_data in self.reviews_data['reviews'].items():
            for review in submission_data['reviews']:
                reviewer_id = review.get('reviewer_id')
                if not reviewer_id or reviewer_id not in reviewer_country_map:
                    continue
                
                reviewer_country = reviewer_country_map[reviewer_id]
                
                # æ”¶é›†è¯„å®¡æ•°æ®
                rating = review.get('rating')
                confidence = review.get('confidence')
                content = review.get('content', {})
                
                # è®¡ç®—æ–‡æœ¬é•¿åº¦
                summary_len = len(content.get('summary', '')) if content.get('summary') else 0
                strengths_len = len(content.get('strengths', '')) if content.get('strengths') else 0
                weaknesses_len = len(content.get('weaknesses', '')) if content.get('weaknesses') else 0
                questions_len = len(content.get('questions', '')) if content.get('questions') else 0
                total_len = summary_len + strengths_len + weaknesses_len + questions_len
                
                country_data = self.country_data[reviewer_country]
                country_data['reviews'].append({
                    'submission_number': int(submission_num),
                    'review_id': review.get('review_id'),
                    'reviewer_id': reviewer_id,
                    'rating': rating,
                    'confidence': confidence,
                    'text_length': total_len
                })
                
                if rating is not None:
                    country_data['ratings'].append(rating)
                if confidence is not None:
                    country_data['confidences'].append(confidence)
                country_data['text_lengths'].append(total_len)
                
                processed_reviews += 1
        
        # æ·»åŠ æœºæ„ä¿¡æ¯
        for institution in self.institutions_data['institutions']:
            country = institution.get('country', 'Unknown')
            if country != 'Unknown':
                self.country_data[country]['institutions'].add(institution['institution_name'])
        
        print(f"âœ… å¤„ç†äº† {processed_reviews} æ¡è¯„å®¡è®°å½•")
        print(f"ğŸ“Š åˆ†æäº† {len(self.country_data)} ä¸ªå›½å®¶/åœ°åŒº")
        
        return dict(self.country_data)
    
    def calculate_country_metrics(self, country_data):
        """è®¡ç®—å›½å®¶æŒ‡æ ‡"""
        print("\nğŸ“ è®¡ç®—å›½å®¶å­¦æœ¯æŒ‡æ ‡...")
        
        country_profiles = {}
        
        for country, data in country_data.items():
            if len(data['reviews']) < 5:  # è‡³å°‘5æ¬¡è¯„å®¡
                continue
            
            # åŸºç¡€ç»Ÿè®¡
            num_reviewers = len(data['reviewers'])
            num_authors = len(data['authors'])
            num_institutions = len(data['institutions'])
            num_reviews = len(data['reviews'])
            
            # è¯„å®¡ç‰¹å¾æŒ‡æ ‡
            avg_rating = np.mean(data['ratings']) if data['ratings'] else 0
            rating_std = np.std(data['ratings']) if len(data['ratings']) > 1 else 0
            median_rating = np.median(data['ratings']) if data['ratings'] else 0
            
            avg_confidence = np.mean(data['confidences']) if data['confidences'] else 0
            confidence_std = np.std(data['confidences']) if len(data['confidences']) > 1 else 0
            
            avg_text_length = np.mean(data['text_lengths']) if data['text_lengths'] else 0
            text_std = np.std(data['text_lengths']) if len(data['text_lengths']) > 1 else 0
            
            # è®¡ç®—å›½å®¶ç‰¹å¾æŒ‡æ ‡
            strictness_score = (10 - avg_rating) / 8 * 100 if avg_rating > 0 else 0
            detail_score = min(avg_text_length / 2000 * 100, 100) if avg_text_length > 0 else 0
            consistency_score = max(0, (1 - rating_std / 4) * 100) if rating_std is not None else 0
            confidence_score = avg_confidence / 5 * 100 if avg_confidence > 0 else 0
            
            # å­¦æœ¯æ´»è·ƒåº¦æŒ‡æ ‡
            reviews_per_reviewer = num_reviews / num_reviewers if num_reviewers > 0 else 0
            author_reviewer_ratio = num_authors / max(num_reviewers, 1) if num_reviewers > 0 else 0
            
            # å›½é™…åŒ–ç¨‹åº¦ï¼ˆåç»­åœ¨è·¨å›½åˆ†æä¸­è®¡ç®—ï¼‰
            
            country_profile = {
                'country': country,
                'academic_scale': {
                    'num_reviewers': num_reviewers,
                    'num_authors': num_authors,
                    'num_institutions': num_institutions,
                    'total_reviews': num_reviews,
                    'reviews_per_reviewer': round(reviews_per_reviewer, 2),
                    'author_reviewer_ratio': round(author_reviewer_ratio, 2)
                },
                
                'reviewing_characteristics': {
                    'avg_rating': round(avg_rating, 2),
                    'rating_std': round(rating_std, 2),
                    'median_rating': round(median_rating, 2),
                    'avg_confidence': round(avg_confidence, 2),
                    'confidence_std': round(confidence_std, 2),
                    'avg_text_length': round(avg_text_length, 0),
                    'text_std': round(text_std, 0)
                },
                
                'country_scores': {
                    'strictness_score': round(strictness_score, 2),
                    'detail_score': round(detail_score, 2),
                    'consistency_score': round(consistency_score, 2),
                    'confidence_score': round(confidence_score, 2)
                },
                
                'tags': self._generate_country_tags(
                    strictness_score, detail_score, consistency_score, 
                    num_reviewers, num_institutions, reviews_per_reviewer
                )
            }
            
            country_profiles[country] = country_profile
        
        print(f"âœ… ç”Ÿæˆäº† {len(country_profiles)} ä¸ªå›½å®¶ç”»åƒ")
        return country_profiles
    
    def _generate_country_tags(self, strictness, detail, consistency, num_reviewers, num_institutions, reviews_per_reviewer):
        """ç”Ÿæˆå›½å®¶æ ‡ç­¾"""
        tags = []
        
        # è§„æ¨¡æ ‡ç­¾
        if num_reviewers >= 200:
            tags.append("å­¦æœ¯å¤§å›½")
        elif num_reviewers >= 50:
            tags.append("å­¦æœ¯ä¸­ç­‰å›½")
        else:
            tags.append("å­¦æœ¯å°å›½")
        
        # ä¸¥æ ¼åº¦æ ‡ç­¾
        if strictness >= 70:
            tags.append("ä¸¥æ ¼è¯„å®¡æ–‡åŒ–")
        elif strictness <= 50:
            tags.append("å®½æ¾è¯„å®¡æ–‡åŒ–")
        else:
            tags.append("ä¸­æ€§è¯„å®¡æ–‡åŒ–")
        
        # è¯¦ç»†åº¦æ ‡ç­¾
        if detail >= 70:
            tags.append("è¯¦ç»†è¯„å®¡é£æ ¼")
        elif detail <= 30:
            tags.append("ç®€æ´è¯„å®¡é£æ ¼")
        
        # ç¨³å®šæ€§æ ‡ç­¾
        if consistency >= 80:
            tags.append("è¯„å®¡æ ‡å‡†ç»Ÿä¸€")
        elif consistency <= 60:
            tags.append("è¯„å®¡æ ‡å‡†å¤šæ ·")
        
        # æ´»è·ƒåº¦æ ‡ç­¾
        if reviews_per_reviewer >= 3:
            tags.append("é«˜åº¦å‚ä¸")
        elif reviews_per_reviewer >= 2:
            tags.append("ç§¯æå‚ä¸")
        else:
            tags.append("é€‚åº¦å‚ä¸")
        
        return tags
    
    def analyze_cross_country_interactions(self, country_data):
        """åˆ†æè·¨å›½äº’è¯„å…³ç³»"""
        print("\nğŸŒ åˆ†æè·¨å›½äº’è¯„å…³ç³»...")
        
        # æ„å»ºå›½å®¶é—´äº’è¯„çŸ©é˜µ
        cross_country_matrix = defaultdict(lambda: defaultdict(lambda: {
            'count': 0,
            'ratings': [],
            'confidences': [],
            'reviews': []
        }))
        
        reviewer_country_map = {}
        for person_id, person_data in self.people_data['people'].items():
            nationality = person_data.get('nationality', 'Unknown')
            roles = person_data.get('roles', [])
            if 'reviewer' in roles:
                reviewer_country_map[person_id] = nationality
        
        # åˆ†æè¯„å®¡è®°å½•ï¼Œæ„å»ºè·¨å›½å…³ç³»
        # æ³¨æ„ï¼šç”±äºç¼ºå°‘æ˜ç¡®çš„ä½œè€…å›½ç±ä¿¡æ¯ï¼Œè¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„æ–¹æ³•
        # å®é™…åº”ç”¨ä¸­éœ€è¦ä»submissionæ•°æ®ä¸­è·å–ä½œè€…å›½ç±
        
        same_country_reviews = defaultdict(list)
        
        for submission_num, submission_data in self.reviews_data['reviews'].items():
            reviewer_countries = []
            
            for review in submission_data['reviews']:
                reviewer_id = review.get('reviewer_id')
                if reviewer_id and reviewer_id in reviewer_country_map:
                    reviewer_country = reviewer_country_map[reviewer_id]
                    reviewer_countries.append((reviewer_country, review))
            
            # åˆ†æåŒä¸€ç¯‡è®ºæ–‡çš„ä¸åŒå›½å®¶å®¡ç¨¿äººè¯„åˆ†å·®å¼‚
            if len(reviewer_countries) >= 2:
                for i, (country1, review1) in enumerate(reviewer_countries):
                    for j, (country2, review2) in enumerate(reviewer_countries):
                        if i != j:
                            rating1 = review1.get('rating')
                            rating2 = review2.get('rating')
                            
                            if rating1 is not None and rating2 is not None:
                                if country1 == country2:
                                    # åŒå›½è¯„å®¡
                                    same_country_reviews[country1].append({
                                        'submission': int(submission_num),
                                        'rating_diff': abs(rating1 - rating2),
                                        'avg_rating': (rating1 + rating2) / 2
                                    })
                                else:
                                    # è·¨å›½è¯„å®¡
                                    interaction_data = cross_country_matrix[country1][country2]
                                    interaction_data['count'] += 1
                                    interaction_data['ratings'].append(rating1)
                                    interaction_data['reviews'].append({
                                        'submission': int(submission_num),
                                        'reviewer_country': country1,
                                        'target_country': country2,
                                        'rating': rating1,
                                        'confidence': review1.get('confidence')
                                    })
        
        print(f"âœ… æ„å»ºäº†è·¨å›½äº’è¯„å…³ç³»ç½‘ç»œ")
        return dict(cross_country_matrix), dict(same_country_reviews)
    
    def detect_geographical_bias(self, cross_country_matrix, same_country_reviews, country_profiles):
        """æ£€æµ‹åœ°åŸŸåè§"""
        print("\nğŸ” æ£€æµ‹åœ°åŸŸåè§...")
        
        geographical_bias = {}
        
        for reviewer_country, targets in cross_country_matrix.items():
            if reviewer_country not in country_profiles:
                continue
            
            # è®¡ç®—è¯¥å›½å¯¹å…¶ä»–å›½å®¶çš„è¯„åˆ†æ¨¡å¼
            all_cross_ratings = []
            target_ratings = {}
            
            for target_country, data in targets.items():
                if data['count'] >= 3 and data['ratings']:
                    avg_rating = np.mean(data['ratings'])
                    target_ratings[target_country] = {
                        'avg_rating': round(avg_rating, 2),
                        'count': data['count']
                    }
                    all_cross_ratings.extend(data['ratings'])
            
            if len(all_cross_ratings) >= 10:  # éœ€è¦è¶³å¤Ÿçš„è·¨å›½è¯„å®¡æ ·æœ¬
                overall_cross_avg = np.mean(all_cross_ratings)
                
                # åŒå›½ vs è·¨å›½è¯„å®¡å·®å¼‚
                same_country_data = same_country_reviews.get(reviewer_country, [])
                same_country_avg = None
                
                if same_country_data:
                    same_ratings = [item['avg_rating'] for item in same_country_data]
                    same_country_avg = np.mean(same_ratings)
                
                home_bias_score = None
                if same_country_avg is not None:
                    home_bias_score = round(same_country_avg - overall_cross_avg, 2)
                
                # æ£€æµ‹å¯¹ç‰¹å®šå›½å®¶çš„åè§
                biased_towards = []
                biased_against = []
                
                for target_country, rating_data in target_ratings.items():
                    if rating_data['count'] >= 5:
                        rating_diff = rating_data['avg_rating'] - overall_cross_avg
                        
                        if abs(rating_diff) >= 0.3:  # æ˜¾è‘—å·®å¼‚é˜ˆå€¼
                            if rating_diff > 0:
                                biased_towards.append({
                                    'target_country': target_country,
                                    'avg_rating': rating_data['avg_rating'],
                                    'difference': round(rating_diff, 2),
                                    'review_count': rating_data['count']
                                })
                            else:
                                biased_against.append({
                                    'target_country': target_country,
                                    'avg_rating': rating_data['avg_rating'],
                                    'difference': round(rating_diff, 2),
                                    'review_count': rating_data['count']
                                })
                
                geographical_bias[reviewer_country] = {
                    'overall_cross_country_avg': round(overall_cross_avg, 2),
                    'same_country_avg': round(same_country_avg, 2) if same_country_avg else None,
                    'home_bias_score': home_bias_score,
                    'total_cross_reviews': len(all_cross_ratings),
                    'biased_towards': sorted(biased_towards, key=lambda x: x['difference'], reverse=True)[:5],
                    'biased_against': sorted(biased_against, key=lambda x: x['difference'])[:5],
                    'cultural_distance_effects': self._analyze_cultural_distance(reviewer_country, target_ratings)
                }
        
        print(f"âœ… å®Œæˆäº† {len(geographical_bias)} ä¸ªå›½å®¶çš„åœ°åŸŸåè§åˆ†æ")
        return geographical_bias
    
    def _analyze_cultural_distance(self, reviewer_country, target_ratings):
        """åˆ†ææ–‡åŒ–è·ç¦»æ•ˆåº”"""
        # ç®€åŒ–ç‰ˆæ–‡åŒ–è·ç¦»åˆ†æ
        # å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„æ–‡åŒ–è·ç¦»æ¨¡å‹
        
        cultural_groups = {
            'East_Asian': ['China', 'South Korea', 'Japan', 'Taiwan', 'Singapore'],
            'Western': ['United States', 'Canada', 'United Kingdom', 'Australia', 'Germany', 'France', 'Netherlands'],
            'South_Asian': ['India', 'Pakistan', 'Bangladesh'],
            'European': ['Germany', 'France', 'Netherlands', 'United Kingdom', 'Italy', 'Spain'],
            'Middle_Eastern': ['Iran', 'Israel', 'Turkey']
        }
        
        reviewer_group = None
        for group, countries in cultural_groups.items():
            if reviewer_country in countries:
                reviewer_group = group
                break
        
        if not reviewer_group:
            return {}
        
        same_culture_ratings = []
        different_culture_ratings = []
        
        for target_country, rating_data in target_ratings.items():
            target_group = None
            for group, countries in cultural_groups.items():
                if target_country in countries:
                    target_group = group
                    break
            
            if target_group:
                if target_group == reviewer_group:
                    same_culture_ratings.append(rating_data['avg_rating'])
                else:
                    different_culture_ratings.append(rating_data['avg_rating'])
        
        result = {}
        if same_culture_ratings and different_culture_ratings:
            same_avg = np.mean(same_culture_ratings)
            diff_avg = np.mean(different_culture_ratings)
            cultural_bias = round(same_avg - diff_avg, 2)
            
            result = {
                'reviewer_cultural_group': reviewer_group,
                'same_culture_avg_rating': round(same_avg, 2),
                'different_culture_avg_rating': round(diff_avg, 2),
                'cultural_bias_score': cultural_bias,
                'same_culture_count': len(same_culture_ratings),
                'different_culture_count': len(different_culture_ratings)
            }
        
        return result
    
    def analyze_international_collaboration(self, country_profiles):
        """åˆ†æå›½é™…åˆä½œæ¨¡å¼"""
        print("\nğŸ¤ åˆ†æå›½é™…åˆä½œæ¨¡å¼...")
        
        collaboration_analysis = {
            'collaboration_matrix': {},
            'openness_rankings': {},
            'collaboration_patterns': {}
        }
        
        # è®¡ç®—å„å›½çš„å›½é™…åŒ–ç¨‹åº¦
        for country, profile in country_profiles.items():
            num_reviewers = profile['academic_scale']['num_reviewers']
            num_institutions = profile['academic_scale']['num_institutions']
            
            # å›½é™…åŒ–æŒ‡æ ‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            # å®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤šå›½é™…åˆä½œæ•°æ®
            international_openness = min(num_institutions / max(num_reviewers, 1), 1.0)
            
            collaboration_analysis['openness_rankings'][country] = {
                'openness_score': round(international_openness, 3),
                'num_reviewers': num_reviewers,
                'num_institutions': num_institutions,
                'reviews_per_reviewer': profile['academic_scale']['reviews_per_reviewer']
            }
        
        # è¯†åˆ«åˆä½œæ¨¡å¼
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„åˆ†æï¼Œå®é™…éœ€è¦æ›´å¤šåˆä½œæ•°æ®
        major_countries = [country for country, profile in country_profiles.items() 
                          if profile['academic_scale']['num_reviewers'] >= 20]
        
        for country in major_countries:
            collaboration_analysis['collaboration_patterns'][country] = {
                'collaboration_type': self._classify_collaboration_type(country_profiles[country]),
                'preferred_partners': [],  # éœ€è¦æ›´å¤šæ•°æ®æ¥åˆ†æ
                'collaboration_strength': self._calculate_collaboration_strength(country_profiles[country])
            }
        
        print(f"âœ… å®Œæˆäº†å›½é™…åˆä½œæ¨¡å¼åˆ†æ")
        return collaboration_analysis
    
    def _classify_collaboration_type(self, country_profile):
        """åˆ†ç±»åˆä½œç±»å‹"""
        num_reviewers = country_profile['academic_scale']['num_reviewers']
        reviews_per_reviewer = country_profile['academic_scale']['reviews_per_reviewer']
        
        if num_reviewers >= 200:
            if reviews_per_reviewer >= 2.5:
                return "Global Academic Hub"
            else:
                return "Major Academic Power"
        elif num_reviewers >= 50:
            if reviews_per_reviewer >= 2.0:
                return "Active Regional Player"
            else:
                return "Emerging Academic Force"
        else:
            return "Specialized Contributor"
    
    def _calculate_collaboration_strength(self, country_profile):
        """è®¡ç®—åˆä½œå¼ºåº¦"""
        num_reviewers = country_profile['academic_scale']['num_reviewers']
        num_institutions = country_profile['academic_scale']['num_institutions']
        
        # ç®€åŒ–çš„åˆä½œå¼ºåº¦è®¡ç®—
        strength = (num_reviewers * 0.7 + num_institutions * 0.3) / 100
        return min(round(strength, 2), 1.0)
    
    def create_geographical_rankings(self, country_profiles, geographical_bias, collaboration_analysis):
        """åˆ›å»ºåœ°åŸŸæ’è¡Œæ¦œ"""
        print("\nğŸ† åˆ›å»ºåœ°åŸŸæ’è¡Œæ¦œ...")
        
        # è¿‡æ»¤ï¼šåªåŒ…å«è‡³å°‘20ä¸ªå®¡ç¨¿äººçš„å›½å®¶
        qualified_countries = [profile for profile in country_profiles.values() 
                             if profile['academic_scale']['num_reviewers'] >= 20]
        
        print(f"ğŸ“Š åˆæ ¼å›½å®¶æ•°é‡ï¼ˆâ‰¥20ä¸ªå®¡ç¨¿äººï¼‰: {len(qualified_countries)}")
        
        rankings = {}
        
        # 1. å­¦æœ¯è§„æ¨¡æ’è¡Œæ¦œ
        rankings['academic_scale'] = {
            'largest_academic_communities': sorted(qualified_countries, 
                                                 key=lambda x: x['academic_scale']['num_reviewers'], reverse=True)[:20],
            'most_institutions': sorted(qualified_countries,
                                      key=lambda x: x['academic_scale']['num_institutions'], reverse=True)[:20],
            'highest_participation': sorted(qualified_countries,
                                          key=lambda x: x['academic_scale']['reviews_per_reviewer'], reverse=True)[:20]
        }
        
        # 2. è¯„å®¡ç‰¹å¾æ’è¡Œæ¦œ
        rankings['reviewing_characteristics'] = {
            'most_strict': sorted(qualified_countries,
                                key=lambda x: x['country_scores']['strictness_score'], reverse=True)[:15],
            'most_lenient': sorted(qualified_countries,
                                 key=lambda x: x['country_scores']['strictness_score'])[:15],
            'most_detailed': sorted(qualified_countries,
                                  key=lambda x: x['country_scores']['detail_score'], reverse=True)[:15],
            'most_consistent': sorted(qualified_countries,
                                    key=lambda x: x['country_scores']['consistency_score'], reverse=True)[:15],
            'highest_confidence': sorted(qualified_countries,
                                       key=lambda x: x['country_scores']['confidence_score'], reverse=True)[:15]
        }
        
        # 3. å›½é™…åŒ–ç¨‹åº¦æ’è¡Œæ¦œ
        openness_data = collaboration_analysis['openness_rankings']
        qualified_openness = {country: data for country, data in openness_data.items()
                            if data['num_reviewers'] >= 20}
        
        rankings['internationalization'] = {
            'most_open': sorted(qualified_openness.items(),
                              key=lambda x: x[1]['openness_score'], reverse=True)[:15],
            'collaboration_types': collaboration_analysis['collaboration_patterns']
        }
        
        # 4. åœ°åŸŸåè§æ’è¡Œæ¦œ
        bias_rankings = []
        for country, bias_data in geographical_bias.items():
            if country in [p['country'] for p in qualified_countries]:
                home_bias = bias_data.get('home_bias_score')
                if home_bias is not None:
                    bias_score = abs(home_bias)
                    bias_rankings.append({
                        'country': country,
                        'home_bias_score': home_bias,
                        'bias_magnitude': bias_score,
                        'total_cross_reviews': bias_data['total_cross_reviews']
                    })
        
        rankings['geographical_bias'] = {
            'most_biased': sorted(bias_rankings, key=lambda x: x['bias_magnitude'], reverse=True)[:10],
            'most_fair': sorted(bias_rankings, key=lambda x: x['bias_magnitude'])[:10]
        }
        
        # 5. æ–‡åŒ–åœˆåˆ†æ
        cultural_analysis = self._analyze_cultural_circles(qualified_countries, geographical_bias)
        rankings['cultural_analysis'] = cultural_analysis
        
        print(f"âœ… åœ°åŸŸæ’è¡Œæ¦œç”Ÿæˆå®Œæˆ")
        return rankings
    
    def _analyze_cultural_circles(self, qualified_countries, geographical_bias):
        """åˆ†ææ–‡åŒ–åœˆç‰¹å¾"""
        cultural_groups = {
            'East_Asian': ['China', 'South Korea', 'Japan', 'Taiwan', 'Singapore'],
            'Western': ['United States', 'Canada', 'United Kingdom', 'Australia', 'Germany', 'France', 'Netherlands'],
            'European': ['Germany', 'France', 'Netherlands', 'United Kingdom', 'Italy', 'Spain'],
            'South_Asian': ['India', 'Pakistan', 'Bangladesh']
        }
        
        cultural_circle_stats = {}
        
        for group_name, countries in cultural_groups.items():
            group_countries = [country for country in qualified_countries 
                             if country['country'] in countries]
            
            if len(group_countries) >= 2:
                # è®¡ç®—æ–‡åŒ–åœˆå¹³å‡ç‰¹å¾
                avg_strictness = np.mean([c['country_scores']['strictness_score'] for c in group_countries])
                avg_detail = np.mean([c['country_scores']['detail_score'] for c in group_countries])
                avg_confidence = np.mean([c['country_scores']['confidence_score'] for c in group_countries])
                total_reviewers = sum([c['academic_scale']['num_reviewers'] for c in group_countries])
                
                cultural_circle_stats[group_name] = {
                    'countries': [c['country'] for c in group_countries],
                    'country_count': len(group_countries),
                    'total_reviewers': total_reviewers,
                    'avg_strictness': round(avg_strictness, 2),
                    'avg_detail_score': round(avg_detail, 2),
                    'avg_confidence': round(avg_confidence, 2),
                    'characteristics': self._get_cultural_characteristics(group_name, avg_strictness, avg_detail)
                }
        
        return cultural_circle_stats
    
    def _get_cultural_characteristics(self, group_name, strictness, detail):
        """è·å–æ–‡åŒ–ç‰¹å¾"""
        characteristics = []
        
        if strictness >= 70:
            characteristics.append("ä¸¥æ ¼è¯„å®¡ä¼ ç»Ÿ")
        elif strictness <= 50:
            characteristics.append("å®½æ¾è¯„å®¡æ–‡åŒ–")
        
        if detail >= 70:
            characteristics.append("è¯¦ç»†åé¦ˆé£æ ¼")
        elif detail <= 30:
            characteristics.append("ç®€æ´åé¦ˆé£æ ¼")
        
        # æ ¹æ®æ–‡åŒ–åœˆæ·»åŠ ç‰¹å®šç‰¹å¾
        cultural_traits = {
            'East_Asian': ["ç»†è‡´è®¤çœŸ", "å±‚æ¬¡åˆ†æ˜"],
            'Western': ["ç›´æ¥å¦ç‡", "åˆ›æ–°å¯¼å‘"],
            'European': ["ä¸¥è°¨è§„èŒƒ", "å¹³è¡¡å®¢è§‚"],
            'South_Asian': ["è¯¦ç»†åˆ†æ", "å»ºè®¾æ€§å»ºè®®"]
        }
        
        if group_name in cultural_traits:
            characteristics.extend(cultural_traits[group_name])
        
        return characteristics
    
    def save_geographical_results(self, country_profiles, cross_country_matrix, geographical_bias, 
                                collaboration_analysis, rankings):
        """ä¿å­˜åœ°åŸŸåˆ†æç»“æœ"""
        print("\nğŸ’¾ ä¿å­˜åœ°åŸŸåˆ†æç»“æœ...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "analysis_results/geographical"
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ä¿å­˜å›½å®¶ç”»åƒ
        country_data = {
            'metadata': {
                'total_countries': len(country_profiles),
                'generation_timestamp': datetime.now().isoformat(),
                'minimum_reviewer_threshold': 5,
                'description': 'ICLRå›½å®¶åœ°åŸŸå­¦æœ¯ç‰¹å¾ç”»åƒ'
            },
            'country_profiles': country_profiles
        }
        
        with open(f"{output_dir}/country_profiles.json", 'w', encoding='utf-8') as f:
            json.dump(country_data, f, ensure_ascii=False, indent=2)
        
        # 2. ä¿å­˜è·¨å›½äº’è¯„çŸ©é˜µï¼ˆç®€åŒ–ç‰ˆï¼‰
        simplified_matrix = {}
        for reviewer_country, targets in cross_country_matrix.items():
            if reviewer_country in country_profiles:
                simplified_matrix[reviewer_country] = {}
                for target_country, data in targets.items():
                    if data['count'] >= 3 and target_country in country_profiles:
                        simplified_matrix[reviewer_country][target_country] = {
                            'interaction_count': data['count'],
                            'avg_rating': round(np.mean(data['ratings']), 2) if data['ratings'] else 0
                        }
        
        cross_country_data = {
            'metadata': {
                'generation_timestamp': datetime.now().isoformat(),
                'description': 'å›½å®¶é—´äº’è¯„å…³ç³»çŸ©é˜µ',
                'minimum_interaction_threshold': 3
            },
            'interaction_matrix': simplified_matrix
        }
        
        with open(f"{output_dir}/cross_country_matrix.json", 'w', encoding='utf-8') as f:
            json.dump(cross_country_data, f, ensure_ascii=False, indent=2)
        
        # 3. ä¿å­˜åœ°åŸŸåè§åˆ†æ
        bias_data = {
            'metadata': {
                'generation_timestamp': datetime.now().isoformat(),
                'description': 'åœ°åŸŸåè§æ£€æµ‹åˆ†æç»“æœ',
                'bias_threshold': 0.3
            },
            'geographical_bias': geographical_bias
        }
        
        with open(f"{output_dir}/geographical_bias_analysis.json", 'w', encoding='utf-8') as f:
            json.dump(bias_data, f, ensure_ascii=False, indent=2)
        
        # 4. ä¿å­˜å›½é™…åˆä½œåˆ†æ
        with open(f"{output_dir}/international_collaboration.json", 'w', encoding='utf-8') as f:
            json.dump(collaboration_analysis, f, ensure_ascii=False, indent=2)
        
        # 5. ä¿å­˜åœ°åŸŸæ’è¡Œæ¦œ
        rankings_data = {
            'metadata': {
                'generation_timestamp': datetime.now().isoformat(),
                'description': 'åœ°åŸŸç»´åº¦å„ç±»æ’è¡Œæ¦œ',
                'minimum_reviewer_threshold': 20
            },
            'rankings': rankings
        }
        
        with open(f"{output_dir}/geographical_rankings.json", 'w', encoding='utf-8') as f:
            json.dump(rankings_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {output_dir}/ ç›®å½•")
        print(f"  ğŸ“„ country_profiles.json - {len(country_profiles)} ä¸ªå›½å®¶ç”»åƒ")
        print(f"  ğŸŒ cross_country_matrix.json - è·¨å›½äº’è¯„çŸ©é˜µ")
        print(f"  ğŸ” geographical_bias_analysis.json - åœ°åŸŸåè§åˆ†æ")
        print(f"  ğŸ¤ international_collaboration.json - å›½é™…åˆä½œåˆ†æ")
        print(f"  ğŸ† geographical_rankings.json - åœ°åŸŸæ’è¡Œæ¦œ")
    
    def run_analysis(self):
        """æ‰§è¡Œå®Œæ•´çš„åœ°åŸŸåˆ†ææµç¨‹"""
        print("ğŸ¯ å¼€å§‹åœ°åŸŸç»´åº¦åˆ†æ...")
        
        # 1. åˆ†æå›½å®¶ç‰¹å¾
        country_data = self.analyze_country_characteristics()
        
        # 2. è®¡ç®—å›½å®¶æŒ‡æ ‡
        country_profiles = self.calculate_country_metrics(country_data)
        
        # 3. åˆ†æè·¨å›½äº’è¯„
        cross_country_matrix, same_country_reviews = self.analyze_cross_country_interactions(country_data)
        
        # 4. æ£€æµ‹åœ°åŸŸåè§
        geographical_bias = self.detect_geographical_bias(cross_country_matrix, same_country_reviews, country_profiles)
        
        # 5. åˆ†æå›½é™…åˆä½œ
        collaboration_analysis = self.analyze_international_collaboration(country_profiles)
        
        # 6. åˆ›å»ºæ’è¡Œæ¦œ
        rankings = self.create_geographical_rankings(country_profiles, geographical_bias, collaboration_analysis)
        
        # 7. ä¿å­˜ç»“æœ
        self.save_geographical_results(country_profiles, cross_country_matrix, geographical_bias, 
                                     collaboration_analysis, rankings)
        
        print(f"\nğŸ‰ åœ°åŸŸåˆ†æå®Œæˆï¼")
        print(f"ğŸŒ åˆ†æäº† {len(country_profiles)} ä¸ªå›½å®¶/åœ°åŒº")
        print(f"ğŸŒ æ„å»ºäº†è·¨å›½äº’è¯„ç½‘ç»œ")
        print(f"ğŸ” å®Œæˆäº†åœ°åŸŸåè§æ£€æµ‹")
        print(f"ğŸ¤ åˆ†æäº†å›½é™…åˆä½œæ¨¡å¼")
        print(f"ğŸ† ç”Ÿæˆäº†å¤šç»´åº¦åœ°åŸŸæ’è¡Œæ¦œ")
        
        return country_profiles, cross_country_matrix, geographical_bias, collaboration_analysis, rankings

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸŒ ICLR åœ°åŸŸç»´åº¦åˆ†æç³»ç»Ÿ")
    print("=" * 60)
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„ - å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è‡ªå®šä¹‰
    data_dir = os.environ.get('ICLR_DATA_DIR', './review-data')
    reviews_path = os.path.join(data_dir, 'reviews.json')
    people_path = os.path.join(data_dir, 'people.json')
    institutions_path = os.path.join(data_dir, 'institutions.json')
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    for path, name in [(reviews_path, "è¯„å®¡æ•°æ®"), (people_path, "äººå‘˜æ•°æ®"), (institutions_path, "æœºæ„æ•°æ®")]:
        if not os.path.exists(path):
            print(f"âŒ {name}æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            return
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = GeographicalAnalyzer(reviews_path, people_path, institutions_path)
    results = analyzer.run_analysis()
    
    print("\nğŸ¯ åœ°åŸŸåˆ†æå®Œæˆï¼å¯ä»¥ç»§ç»­è¿›è¡Œä¸‹ä¸€ä¸ªåˆ†ææ¨¡å—...")

if __name__ == "__main__":
    main()